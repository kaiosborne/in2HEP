{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. $H\\rightarrow b\\bar{b}$ via Machine Learning \n",
    "\n",
    "Machine learning algorithms are one of the ways with which we create Artificial Intelligence. The distinguishing featuere of machine learning compared to usual programming is training. Instead of programming the steps to get to the solution to a problem we program a machine learning algorithm to be trained to learn the steps towards the desired solution. \n",
    "\n",
    "On the ATLAS $H\\rightarrow b\\bar{b}$ analysis, using machine learning allows us to extract information about the correlations between the different kinematic variables to improve discrimination between signal and background. \n",
    "\n",
    "In this exercise you will build and train a Neural Network algorithm to classify $H\\rightarrow b\\bar{b}$ events instead of using sequential cuts. \n",
    "\n",
    "### 1.1 What is a Neural Network?\n",
    "\n",
    "The neural network model is loosely based on the human brain. A Neuron receives a number of input signals, these signals are then processed at the neuron which passes on a new signal (fires) to the next neuron only if a certain condition is met. \n",
    "\n",
    "A neural network is a collection of artificial neurons organised in layers (as shown in the image below) that connect together allowing the neural network to learn complexities and make sophisticated decisions. The artificial neurons work by simple multiplication between the input signals (variables) coming into the node and a set of weights. If the produce of this multiplication is above a certain threshold, the neuron fires! \n",
    "\n",
    "\n",
    "![Neural Network](https://i.stack.imgur.com/OH3gI.png)\n",
    "\n",
    "The neurons must be trained to process the signal appropriately so as to maximise the accuracy in decision making. To understand this, let's go back to the human brain analogy. Say you were teaching your younger sibling how to recognise numbers. You would repeatedly show them pictures of numbers and tell them which one is which. You might test their knowledge by giving them a new image and then seeing whether they recognised what digit it was. You might then praise them for getting it right and correct them if they got it wrong. \n",
    "\n",
    "\n",
    "Neurons are trained in a similar way. To train a neural network to learn how to recognise handwritten digits we would give it thousands of images of labelled handwritten digits. It will pass these images through the network in the form of numbers between 0 and 1, compute the product between these inputs (the image in the form of numbers) and the weights at all neurons. The final product at the end of the  neural network will be used to reach a decision. The training process updates the weights such that the accuracy is maximised. \n",
    "\n",
    "This process is similar to maximisation (or minimisation) problems you may have done in A-Level Maths using differentiation to find the minimum/maximum value of function. \n",
    "\n",
    "All this might sound a bit confusing! Don’t worry it is a lot to take in within a short space of time. Ask your mentors about anything you’re unsure about. \n",
    "\n",
    "We're now going to learn how to build and apply a neural network in Python using the Keras library. \n",
    "\n",
    "\n",
    "### 1.2 Neural Networks in Keras\n",
    "\n",
    "The algorithm for doing the $H\\rightarrow b\\bar{b}$ can be summarised with the following 6 steps:\n",
    "\n",
    "* Import libraries and load data.\n",
    "* Build neural network. \n",
    "* Training Neural Network. \n",
    "* Make decisions about events using the Neural Network. \n",
    "* Calculate sensitivity. \n",
    "\n",
    "\n",
    "### Importing libraries and loading \n",
    "\n",
    "The Keras library is a free open-source tool to quickly and easily develop with neural networks. It does a lot of the heavy lifting for us making it an ideal tool for prototyping. Just like any popular Python library, it is well documented with guides explaining how to use it. These are available here: https://keras.io/\n",
    "\n",
    "In this exercise, your mentors will guide you through a lot of the code that has already been written for you so that you can focus specifically on building the neural network. It is still valuable to understand what is going on so make sure you ask questions! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: wget\n",
      "zsh:1: command not found: wget\n",
      "zsh:1: command not found: wget\n",
      "zsh:1: command not found: wget\n"
     ]
    }
   ],
   "source": [
    "# Download the data files if we need them. If you download the repo as a ZIP, \n",
    "# this cell is not needed. If running on colab, it will automatically download\n",
    "# all required data.\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "data_path = Path('../data-v2/VHbb_data_2jet.csv')\n",
    "train_data_path = Path('../data-v2/VHbb_data_2jet_train.csv')\n",
    "val_data_path = Path('../data-v2/VHbb_data_2jet_val.csv')\n",
    "test_data_path = Path('../data-v2/VHbb_data_2jet_test.csv')\n",
    "class_path = Path('ucl_masterclass.py')\n",
    "if not data_path.exists():\n",
    "    !wget -P ../data-v2/ https://raw.githubusercontent.com/nikitapond/in2HEP/master/data-v2/VHbb_data_2jet.csv\n",
    "else:\n",
    "    print(\"Data file already found\")\n",
    "\n",
    "if not train_data_path.exists():\n",
    "    !get -P ../data-v2 https://raw.githubusercontent.com/nikitapond/in2HEP/master/data-v2/VHbb_data_2jet_train.csv\n",
    "else:\n",
    "    print(\"Train data file already found\")\n",
    "\n",
    "if not val_data_path.exists():\n",
    "    !get -P ../data-v2 https://raw.githubusercontent.com/nikitapond/in2HEP/master/data-v2/VHbb_data_2jet_val.csv\n",
    "else:\n",
    "    print(\"Validation data file already found\")\n",
    "\n",
    "if not test_data_path.exists():\n",
    "    !get -P ../data-v2 https://raw.githubusercontent.com/nikitapond/in2HEP/master/data-v2/VHbb_data_2jet_test.csv\n",
    "else:\n",
    "    print(\"Test data file already found\")\n",
    "\n",
    "if not class_path.exists():\n",
    "    !wget https://raw.githubusercontent.com/nikitapond/in2HEP/master/notebooks/ucl_masterclass.py\n",
    "else:\n",
    "    print(\"Required custom classes already found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from ucl_masterclass import *\n",
    "from sklearn.preprocessing import scale\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.models import model_from_yaml\n",
    "from keras.layers import Input, Dense, Dropout, Flatten\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "from time import time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the training, validation, and testing data\n",
    "df_train = pd.read_csv(train_data_path)\n",
    "df_val = pd.read_csv(val_data_path)\n",
    "df_test = pd.read_csv(test_data_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation\n",
    "\n",
    "As dicussed in lectures, ML models perform better if the data passed to them has all variables are of similar scale. There are a few ways to do this. Some of the most popular are:\n",
    "- Min max scaling: Scale all our data so values are between 0 and 1\n",
    "- Standard scaling: Calculate the mean and standard deviation (std) of each variable, then take $v' = (v - \\mu)/\\sigma$ Where $\\mu$ and $\\sigma$ are the mean and std respectedly.\n",
    "- Normalisation: Scale so all values are between -1 and 1\n",
    "\n",
    "Below, we use the 'minmax' scaler with the predefined function. You can also try 'norm' and 'standard'.\n",
    "\n",
    "The function below returns 5 total variables. They are:\n",
    "- x_train: The training inputs for the model\n",
    "- y_train: The training labels\n",
    "- w_train: The training weights give a value to how likely a given event is to occur at the LHC, and so ensures the model is optimised based upon the relative abundance of the different processes\n",
    "- dset_val: A tuple of the form (x_val, y_val) that containing data for validation. We return it as a tuple, as this is the easiest way to pass it in model.fit\n",
    "- dset_test: TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['dRBB','mBB','MET','Mtop','pTV',]\n",
    "\n",
    "(x_train, y_train, w_train, \n",
    " dset_val, dset_test) = scale_prepare_data(df_train, df_val, df_test, variables, scaler='standard')\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training \n",
    "\n",
    "The neural network is given a set of training events that have a Class label of 1 for signal and 0 for background. During the training phase, the neural network goal is to *learn* how to map input variables given to it (kinematic and topological quantities of the event) to 0 for background and 1 for signal. \n",
    "\n",
    "To ensure that the neural network is learning general features about the signal and background process and not just **artifacts** unique to the training data set, we split the data set into a training, validation, and testing set. We train on the train data, and evaluate each epoch on the validation data, to see how the model is training. We then finally evaluate on the testing dataset, to ensure we haven't over optimised for the training/validation set.\n",
    "\n",
    "**In the section below we extract the input (x) and target values (y) used to train the neural network.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Neural Network\n",
    "\n",
    "To build the neural network we will be using the Keras *Sequential* model. This works by allowing us to add layers into our model using the following line of code which adds a layer with 10 neurons. \n",
    "```python\n",
    "model.add(Dense(units=10,activation='relu')) # adds a layer with 10 neurons. \n",
    "```\n",
    "\n",
    "By sequentially adding layers you can create a fully connected deep neural network within minutes! \n",
    "\n",
    "\n",
    "**Ask your mentor to explain what the following terms are:**\n",
    "* Activiation\n",
    "* Loss\n",
    "* Gradient Descent \n",
    "\n",
    "\n",
    "\n",
    "### Task\n",
    "Earlier you developed an analysis for $H\\rightarrow b\\bar{b}$ using sequential cuts on 'dRBB','mBB','MET','Mtop', and'pTV'. You will now build a neural network to classify the simulated events as signal or background. \n",
    "\n",
    "After discussing neural network architectures with your mentor you will: \n",
    "\n",
    "* In the code cell below, define the architecture for your neural network. \n",
    "* Set the batch size used in training and the number of epochs in training. \n",
    "\n",
    "Once you have done this run the code to start training your neural network. The time taken to train the network will be printed at the end. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier(variables):\n",
    "    \"\"\"\n",
    "    Creates a model for higgs to bb classification\n",
    "    \n",
    "    returns: Keras model\n",
    "    \"\"\"\n",
    "    num_variables = len(variables)\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    # The input layer\n",
    "    model.add(Dense(units=num_variables,input_dim = num_variables,activation='relu'))\n",
    "    \n",
    "    # Add hidden layers here\n",
    "    # ======================\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='SGD', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "\n",
    "# Create and compile model\n",
    "\n",
    "# Set these parameters\n",
    "# ====================\n",
    "epochs = 5\n",
    "batchSize = 64\n",
    "# train\n",
    "model = classifier(variables)\n",
    "\n",
    "history = model.fit(x_train, y_train, sample_weight = w_train,\n",
    "        validation_data = dset_val, \n",
    "        epochs=epochs, batch_size=batchSize,verbose = 1)\n",
    "\n",
    "print(\"model trained in \" + str(round(time()-start,2))+\"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating our Neural Network\n",
    "\n",
    "The code below will now test your neural networks on unseen events. Remember if a neural network was trained on the odd data set and hence it will be tested on the even data set. The neural network is used to classify the events and calculate the sensitivity using the neural network scores plotted in the histogram below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['decision_value'] = model.predict(dset_test[0])\n",
    "print(\"A sensitivity of\", round(sensitivity_NN(df_test)[0],2),'was achieved')\n",
    "nn_output_plot(df_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warm up tasks:\n",
    "\n",
    "* Try training the model multiple times, storing the sensitivity each time in a list\n",
    "* How much do these sensitivies differ for each run? What is the mean sensitivity, and whats the standard deviation?\n",
    "* Which scaling method results in the highest sensitivity, and the lowest standard deviation?\n",
    "\n",
    "In general, we expect the model to perform slightly differently each time we train it, due to the stochastic nature of the training. We need to make sure then, that we train and evaluate a model multiple times, to ensure any performance difference is due to optimisations, and not a random performance fluctuation. \n",
    "\n",
    "While overall model performance, in the form of mean sensitivity, is important, having a model structure which results in low sensitivity deviations, as this ensures the model will be robust, and more likely perform well in a larger dataset. \n",
    "\n",
    "We'd recommend then, to train each model a few times (5 or so should be sufficient), exlcuding the smallest and largest value, and taking the mean and std. This can be done using the provided method:\n",
    "\n",
    "```python\n",
    "mean_std_sensitivity(sensitivities, drop=1)\n",
    "```\n",
    "\n",
    "This will exclude the largest and smallest sensitivity, and calculates the mean and standard deviation, and ensure any random outliers are excluded.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary \n",
    "\n",
    "Neural Networks can learn correlations between variables and create a better understanding of the classification process hence leading to better signal sensitivity. They have been very popular in industry and regularly win competitions on the Kaggle machine learning forum. If you are interested in doing more machine learning this is a free 'nanodegree' on deep learning: https://www.youtube.com/watch?v=vOppzHpvTiQ&list=PL2-dafEMk2A7YdKv4XfKpfbTH5z6rEEj3\n",
    "\n",
    "**This material was produced by hackingEducation**  \n",
    "<img src=\"images/logo-black.png\" width=\"50\" align = 'left'/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phas0056_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "9197234e3884fac50101dc52cb3ee22708d202ecd3cf3150efd67ff473835ea5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
